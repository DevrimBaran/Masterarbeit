\chapter{Methodology}\label{ch:methodology}
To achieve the goal that is defined in \cref{sec:objective}, we first need to find all wait-free data structures that could be used for \ac{IPC} through shared memory in \ac{HRTS}. To do this a method was used that is more known from mapping studys or literature reviews. Multiple python scripts were implemented to do this \cite{githubMA}. A web scraper script was written to scrape over google scholar with the following querys:
\begin{itemize}
   \item "wait-free queue"
   \item "wait-free" ("mpmc" OR "multi-producer multi-consumer" OR "multi-writer multi-reader" OR "many-to-many") "queue"
   \item "wait-free" ("mpsc" OR "multi-producer single-consumer" OR "single-writer multi-reader" OR "many-to-one") "queue"
   \item "wait-free" ("spsc" OR "single-producer single-consumer" OR "single-writer single-reader" OR "one-to-one") "queue"
   \item "wait-free" ("spmc" OR "single-producer multi-consumer" OR "multi-writer single-reader" OR "one-to-many") "queue"
\end{itemize}
In google scholar a whitespace is considered as an AND. The rest is interpreted as read. With this approach i got a list of 1324 papers. The papers were then written into a csv file split into query, rank (number of paper), title, year, authors, venue, citations, abstract snippet, full\_abstract and url with ";" as an delimiter. To extract all of this the information in google scholar was extracted and then for the full abstract the scraper went onto the source url and extracted the abstract there. If the url was a direct pdf link, a pdf reader was used to find the abstract. If an abstract was not extractable (some source site which was not considered or other problems), "ABSTRACT\_NOT\_FOUND" was written instead or if the paper was accessible the full paper was written instead into that cell. Because a lot of scientific web pages will put ceptchas if continuously requests are made undetected\_chromedriver was importet and used as the web driver. It is an enhanced version of chromedriver which bypasses anti bot detections. After that I also implemented a regex analyzer to analyze the abstracts of the found papers on the words "lock\-free", "wait\-free", and "obstruction\-free" and also again without a hyphon inbetween these words. If these keywords were not found in the abstract or the abstract contained the flag "ABSTRACT\_NOT\_FOUND" the paper was removed from the csv. This left 475 papers that contained at least one of these words in their abstract. After that the duplicates were removed by the algorithm, which left 325 papers. The duplicates were removed by checking the url of the paper. Now what was left had to be manually analyzed to see if the paper was relevant for the topic. Since libre office and microsoft excel has a limit of 32.767 charachters per cell a abstract splitter had to be build to split the abstract into multiple cells. Analyzing was done by reading the paper and checking if the paper was developing an wait-free fifo queue. While dooing that also backward and forward search was done to even find more papers. In the end 17 papers were left from the 325 papers and 3 more paper were found by backward and forward search of the papers that were left. The papers were then split into 4 contention categories:
\begin{itemize}
   \item \ac{MPMC} queues \cite{Kogan2011WaitFreeQueues,FeldmanDechev2015WaitFreeRingBuffer,kogan2012methodology,FeldmanDechevV2,FeldmanDechevV3,RamalheteQueue,wCQWaitFreeQueue,Verma2013Scalable,FastFetchAndAddWaitFreeQueue}
   \item \ac{MPSC} queues \cite{WangCacheCoherent,adampsc,jiffy,JayantiLog,Drescher2015GuardedSections}
   \item \ac{SPMC} queues \cite{Mate√≠spmc}
   \item \ac{SPSC} queues \cite{Lamport1983SPSCCircularBuffer,torquati2010singleproducersingleconsumerqueuessharedcache,Aldinucci2012EfficientSync,Wang2013BQueue,MaffioneCacheAware,ffq}
\end{itemize}
Now the wait-free fifo queues had to be compared performance wise. Some papers were just improvements of other papers so only the improved version was used for the comparison. Some other papers showed multiple ways of implementing a wait-free fifo datastructure. So in the end we have 6 \ac{MPMC} queues, 4 \ac{MPSC} queues, 1 \ac{SPMC} queue and 11 \ac{SPSC} queues.