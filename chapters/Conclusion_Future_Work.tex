\chapter{Conclusion and Future Work}\label{ch:conclusion}

\section{Conclusion}

This thesis investigated wait-free data structures for \ac{IPC} through shared memory for \acsp{RTS}, with implementations in Rust. The primary goal was to identify and evaluate the best wait-free algorithms that can provide predictable timing guarantees essential for \ac{HRTS}.

Through systematic analysis of 20 different wait-free queue implementations across four contention categories (\ac{SPSC}, \ac{MPSC}, \ac{SPMC}, and \ac{MPMC}), several key insights emerged. First, specialisation matters significantly in concurrent data structures. The benchmarks demonstrated that algorithms optimised for specific producer-consumer settings outperform solutions built for other contention categories by factors of 2 to 10. This performance gap justifies maintaining separate implementations for different contention scenarios rather than as an example relying on a single \ac{MPMC} queue for all use cases.

Cache optimisation and batching proved to be a critical factor for performance. The \acf{BLQ} achieved the best \ac{SPSC} performance at 65.2 milliseconds for 35 million items, due to its cache-aware design that minimises false sharing by cache line separation and batching through a producer which accumulates data before pushing them and making them visible for a consumer. Similarly, DQueue was the best performing queue in the \ac{MPSC} category by using batching. These results confirm that understanding and optimising cache hierarchies is more important than just proven better theoretical algorithmic time complexity like \ac{JPQ} in practice.

The implementation challenges of adapting thread-based algorithms to \ac{IPC} revealed important practical considerations. Dynamic memory allocation, which is simpler in thread-based implementations, required significant redesign for shared memory contexts. All queues using dynamic allocation had to be modified to use pre-allocated memory pools, introducing additional complexity but ensuring position-independent operation across different process address spaces. This adaptation particularly impacted the performance of \ac{dSPSC} and \ac{uSPSC} queues.

The Rust programming language was well-suited for implementing these algorithms. Its ownership model and explicit memory ordering semantics allowed precise control over synchronisation while maintaining memory safety. The unsafe blocks required for shared memory operations were well-contained, and the type system helped prevent common concurrency bugs during development. The achieved test coverage of 81.12\% function coverage and 70.03\% line coverage demonstrates that most code paths could be reliably tested despite the complexity of concurrent operations. These tests with the additional correctness check in the benchmark also formed the validation that these queues work as expected.

During the thesis it was found out that the recommended wait-free queues for real-time \ac{IPC} are \acf{BLQ} for \ac{SPSC}, DQueue for \ac{MPSC}, David Queue for \ac{SPMC}, and \ac{YMC} or Verma Queue for \ac{MPMC} depending on how high the contention is.

These findings contribute to \ac{RTS} by providing concrete performance data for wait-free algorithms under realistic \ac{IPC} workloads, and offering production-ready Rust implementations suitable for safety-critical applications.

\section{Future Work}
While this thesis provides a comprehensive evaluation of existing wait-free algorithms for \ac{IPC}, several areas need further research.

\subsection{Dynamic Wait-Free Memory Allocation for Shared Memory \acf{IPC}}
The most problematic area during implementation was the lack of wait-free dynamic memory allocation schemes suitable for shared memory contexts. All algorithms requiring dynamic allocation had to be modified to use pre-allocated pools, which limits flexibility and potentially wastes memory. Future research should investigate wait-free memory allocators specifically designed for shared memory \ac{IPC}.

Such allocators need to address the following challenge. They must operate without a global heap, as each process has its own address space. So such an allocator would need to share the address space of the shared memory region across all processes in a wait-free manner. Also, it needs to function so that dynamically the shared memory region can shrink and grow as needed while sharing the new memory region bounds to the processes while still maintaining wait-freedom.

A wait-free shared memory allocator would enable more flexible data structures and could allow the exact implementation of dynamic queues like \ac{dSPSC} and \ac{uSPSC} that currently cannot be that dynamic with a pre-allocated pool.

\subsection{Integration with \acf{RTOS}}
The current benchmarks run on a Linux system, which introduces timing variations from scheduling and interrupts. Future work should evaluate these algorithms on \ac{RTOS} like RTEMS or QNX to see the performance in a \ac{RTS} environment. This would provide insights into how these wait-free queues perform under real-time constraints and scheduling policies.