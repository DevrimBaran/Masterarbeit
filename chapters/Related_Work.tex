\chapter{Related Work}\label{ch:related-work}

The early foundations regarding wait-freedom were laid indirectly by Leslie Lamport in 1983 \cite{Lamport1983SPSCCircularBuffer}. While his work did not directly address or formally define wait-freedom or lock-freedom, it laid the groundwork for Maurice Herlihy to define wait-freedom \cite{herlihy1991wait}. \\
In 1983, Leslie Lamport introduced a formal method for writing and proving the correctness of any concurrent module in a simple and modular way, independent of the data structure used, which he referred to as modules. These modules consist of three components: 
\begin{itemize}
   \item state functions, which are abstract variables describing the module's state.
   \item initial conditions, which are predicates on the state functions.
   \item properties, which are a mix of safety and liveness requirements.
\end{itemize}
Safety requirements define what must never happen (e.g., a queue must never drop an element). In contrast, liveness requirements define what must eventually happen (e.g., a non-empty queue must eventually allow dequeueing to occur). He also defines the usage of action sets and environment constraints, which separate the module action from the environments (e.g., the program in which the data structure runs). For example, a \ac{FIFO} queue specification would include:
\begin{itemize}
   \item State Functions: queue contents, operation parameters, return values.
   \item Initial Conditions: queue starts empty.
   \item Safety Condition: queue maintains \ac{FIFO} ordering.
   \item Liveness Condition: dequeue operation will eventually return a value.
\end{itemize}
This systematic methodology to prove the correctness of concurrent data structures laid the necessary groundwork for later developments. \cite{Lamport1983SPSCCircularBuffer}

Building on methodologies to prove concurrent data structure correctness, Herlihy and Wing provided linearizability as a correctness condition for concurrent objects, which is a guarantee that every operation performed appears to take effect instantaneously at some point between the call and return of the operation \cite{HerlihyLinearizability}. This correctness condition was then used to formalise wait-freedom in 1991 \cite{herlihy1991wait}. In the latter work, Herlihy proved that any sequential data structure can be transformed into a wait-free concurrent data structure \cite{herlihy1991wait}. A wait-free data structure must satisfy the following three constraints: 
\begin{itemize}
   \item Linearisability: operations take effect instantaneously at some point between the call and return of the operation \cite{herlihy1991wait}.
   \item Bounded steps: operations end in a finite number of steps \cite{herlihy1991wait}.
   \item Independence: operations finish regardless of other processes' execution (for later understanding: a process waiting for another process for a maximum number of time and then returning an error if that time is exceeded would still be considered wait-free, since it will finish regardless of the other process) \cite{herlihy1991wait}.
\end{itemize}

Herlihy's universal construction and principles (or work that builds upon his work) appear conceptually throughout all of these wait-free algorithms \cite{Kogan2011WaitFreeQueues,FeldmanDechev2015WaitFreeRingBuffer,kogan2012methodology,FeldmanDechevV2,FeldmanDechevV3,RamalheteQueue,wCQWaitFreeQueue,Verma2013Scalable,FastFetchAndAddWaitFreeQueue,WangCacheCoherent,adampsc,jiffy,JayantiLog,Drescher2015GuardedSections,Mate√≠spmc,torquati2010singleproducersingleconsumerqueuessharedcache,Aldinucci2012EfficientSync,Wang2013BQueue,MaffioneCacheAware,ffq}. \cite{herlihy1991wait}

Additionally, in 1983, Lamport presented a concurrent lock-free \ac{FIFO} queue implementation using a circular buffer. It works by using an array Q with two pointers, HEAD and TAIL, where elements are added at TAIL and removed at HEAD. The producer first checks if the queue is full by testing if TAIL - HEAD equals the queue capacity m, and if so, it busy-waits. When space is available, it transfers the element bit-by-bit into Q at position TAIL modulo m, then atomically increments TAIL to commit the addition. Similarly, the consumer checks if the queue is empty by testing if TAIL - HEAD equals 0, and if so, it busy-waits. When an element is available, it extracts the element bit-by-bit from Q at position HEAD modulo m using shift operations, then atomically increments HEAD to commit the removal. This means that while data is being shifted, other operations can observe partial states, but the queue still maintains its \ac{FIFO} properties correctly because an element is only considered "in" the queue after TAIL is incremented and only considered "removed" after HEAD is incremented. Even though busy-waits are used, the queue will eventually fill and be dequeued, so the producer and consumer will finish in a finite number of steps, making the Lamport queue wait-free, even though that term was not defined at the time. \cite{Lamport1983SPSCCircularBuffer} 

The Lamport queue is the basis of many more wait-free queues later invented, discussed in \cref{ch:choosing-the-optimal-wait-free-data-structure}.

Kogan and Petrank later invented a method called fast-path slow-path, where, first, a lock-free method (the fast-path) is typically used to attempt to complete an operation, as lock-free algorithms are generally faster than wait-free algorithms. A maximum number of steps bounds these lock-free paths, and if the operation does not complete within that bound, the algorithm tries to complete the operation using a wait-free method (the slow path). Therefore, in cases where the fast path succeeds frequently without switching to the slow path, the algorithm generally completes in a shorter time than a pure wait-free algorithm. This method is used by two algorithms, with one of them having a great performance advantage, which will be demonstrated later in this thesis in \cref{ch:choosing-the-optimal-wait-free-data-structure}. \cite{kogan2012methodology}
