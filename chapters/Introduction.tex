\chapter{Introduction}\label{ch:introduction}

\section{Motivation}\label{sec:motivation}

In modern manufacturing and automation, control systems must operate under strict timing constraints to function reliably. If a system fails to meet these constraints, unexpected delays can disrupt processes, leading to instability or even hazardous failures in safety-critical environments. For this reason, \ac{RTS} and low-level programming languages like C or Rust are widely used to ensure predictable execution times.

To achieve these strict timing requirements, many real-time applications involve multiple tasks that must run concurrently and share resources efficiently. Without proper synchronisation, problems such as data corruption or race conditions can occur, leading to unpredictable behaviour. Traditional synchronisation methods with locks are commonly used to manage access to shared resources by blocking processes so that only one process at a time accesses the shared resource to exchange data in a proper way. However, these blocking mechanisms introduce difficulties in real-time settings. Since traditional synchronisation methods require processes to wait for resource availability, they can lead to unpredictable response times through potential deadlocks, process starvations, or priority inversions. Such unpredictability is unacceptable in such systems that require strict timing guarantees. \cite{herlihy1991wait, brandenburg2019multiprocessorrealtimelockingprotocols, kode2024analysisSynchronization}

To overcome these limitations, synchronisation techniques without any blocking mechanisms are required. A lock-free algorithm for instance functions without any locking mechanism thus no blocking. This guarantees that at least one process completes in a finite number of steps, regardless of contention (multiple processes try to access the same shared resource). This property ensures that at least the system will still work even though one process might be lagging. The only problem is that this will not handle starvation since there is no guarantee that every process will finish its task. \cite{kogan2012methodology}

While lock-free algorithms represent an improvement, wait-free algorithms guarantee that every operation completes in a finite number of steps, regardless of contention. This property ensures system responsiveness and predictability, which are essential to define timing constraints for real-time applications. \cite{kogan2012methodology, herlihy1991wait, brandenburg2019multiprocessorrealtimelockingprotocols}

These synchronisation mechanisms are particularly important in the context of \ac{IPC}, which is needed in \ac{RTS}. \ac{IPC} allows processes to exchange data efficiently, but its performance is heavily influenced by the synchronisation techniques used. Traditional \ac{IPC} mechanisms, which often rely on blocking some processes. Wait-free data structures offer a promising alternative by ensuring that communication operations complete within predictable time bounds. \cite{timnat2014practical, michael1996simple, huang2002improvingWaitFree, pellegrini2020relevancewaitfreecoordinationalgorithms}

To implement the earlier addressed synchronisation techniques properly, the choice of programming language is important. The Rust programming language provides useful features for implementing real-time synchronisation mechanisms. Its ownership model and strict type system prevent data races and enforce safe concurrency. Additionally, Rust offers accurate control over system resources, making it a good choice for real-time applications that need both low latency and high reliability. \cite{xu2023rust, sharma2024rustembeddedsystemscurrent}

The concepts and methods introduced here, including \ac{RTS}, \ac{IPC}, synchronisation techniques and their difficulties, wait-free synchronisation, and the Rust programming language are explored in greater depth in \cref{ch:background}. 

\section{Objective}\label{sec:objective}
The primary goal of this research is to find the best wait-free data structures that can be used to implement a wait-free synchronisation for \ac{IPC} through shared memory in \ac{RTS} using Rust. To do so, this study aims to:

\begin{itemize}
\item Identify and analyse existing wait-free synchronisation techniques for \ac{IPC} through shared memory for \ac{RTS}.
\item Implement, validate, and compare the performance of existing wait-free synchronisation mechanisms for \ac{IPC} through a shared memory for real-time scenarios with each other.
\item Choose and analyse which wait-free data structure for \ac{IPC} through shared memory in a real-time setting using Rust is best suited.
\end{itemize}

\section{Structure of the Thesis}\label{sec:structure-of-the-thesis}
To describe on how to achieve this goal first a depper knowledge base will be given in \cref{ch:background} to understand the concepts used in this work. Then in \cref{ch:related-work} related work leading to concepts needed for this work will be presented. After that in \cref{ch:methodology} the methodology explaining how the papers including the wait-free queues were found will be explained. Next in \cref{ch:choosing-the-optimal-wait-free-data-structure} it will be explained which data-structure was chosen and the wait-free queues found will be explained. Afterwards in \cref{ch:implementation} it will be explained on how to implement the important details of the queues without explaining their logic again. Following that in \cref{ch:results} the results of the benchmarks will be presented and analysed and finally, in \cref{ch:conclusion} a conclusion will be drawn and future work will be discussed.